import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.ResponseEntity;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import java.util.*;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

@Service
public class PandaAccountService {

    @Autowired
    private BaseService baseService;
    @Autowired
    private NotificationRepository notificationRepository;

    private final Map<String, String> eventTypemap = new HashMap<>();

    @Transactional
    public PandaRunStatusDto incrementalLoad(String queryName) throws BusinessException {

        LoadDto loadDto = null;
        String graphQLResponse = null; //insert record into load table
        loadDto = insertLoad(queryName);
        //STEP-1 : Get query from spring cloud config
        Optional<PandaDataRadixConfigProperties.RadixQueryProperties> radixQueryProperties = baseService.getRadixQueryProperties(queryName);
        if(radixQueryProperties.isEmpty()){
            throw new BusinessException("Query name is incorrect");
        }
        Map<String, String> entityAndFilterColumn = baseService.getEntitiesAndFilterColumnsByQuery(radixQueryProperties);
        //STEP-2 : Get Filter from Notification table
        Map<String, Object> filters = getFilters(entityAndFilterColumn);
        //Utility method later // this might not be required
        String currentFilter= getCurrentFilter(entityAndFilterColumn);
        //get the eventType map from the notification table
        Map<String, String> eventTypeMap = getEventTypeMap();
        // Return empty values if eventTypeMap is empty
        if (eventTypeMap.isEmpty()) {
            updateStatus(loadDto, "SUCCESS"); // need to check if this is the right place to update this.
            return PandaRunStatusDto.builder().runId(loadDto.getRunId()).fileContent(null).build();
        }
        //STEP-4 : Execute the query
        String graphQLQuery = radixQueryProperties.get().getRadixQuery();
        
        // Prepare sublists for filters to ensure only 100 IDs are processed at a time
        List<List<String>> subLists = prepareSubLists(new HashSet<>(filters.values()), 100);

        for (List<String> subList : subLists) {
            Map<String, Object> subListFilters = new HashMap<>(filters);
            subListFilters.put(entityAndFilterColumn.values().iterator().next(), subList);

            ResponseEntity<GraphqlResponse> response = baseService.getResponse(graphQLQuery, subListFilters);

            //code to get the operation name from the graphql query //Regular expression pattern to match the operation name
            Pattern pattern = Pattern.compile("^(\\s*(query|mutation|subscription)\\s+(\\w+).*)", Pattern.DOTALL);
            Matcher matcher = pattern.matcher(graphQLQuery);
            String operationName ="";
            if (matcher.find()) {
                String operationType = matcher.group(1);
                operationName = matcher.group(2);
                System.out.println("Operation Type: " + operationType);
                System.out.println("Operation Name: " + operationName);
            } else {
                System.out.println("Operation name not found.");
            }

            List<String> headers = extractKeysFromQuery(graphQLQuery, operationName);
            // System.out.println(headers);
            ObjectMapper objectMapper = new ObjectMapper();
            try {
                graphQLResponse = objectMapper.writeValueAsString(response.getBody());
            } catch (JsonProcessingException e) {
                throw new RuntimeException(e);
            }
            // StringWriter stringWriter = new StringWriter();
            String result = storeDataInTXT(graphQLResponse, headers, eventTypeMap, loadDto, operationName, currentFilter);
            // Accumulate results if needed, or handle each subList result separately
        }

        return PandaRunStatusDto.builder().runId(loadDto.getRunId()).fileContent(result.getBytes()).build();
    }

    // Adjusted prepareSubLists method to fit this class
    private List<List<String>> prepareSubLists(Set<String> allAccountCodes, int maxSize) throws BusinessException {
        if (allAccountCodes == null || allAccountCodes.isEmpty()) {
            throw new BusinessException("Account code list must not be empty");
        }
        List<String> accountCodesList = new ArrayList<>(allAccountCodes);
        List<List<String>> subLists = new ArrayList<>();
        for (int i = 0; i < accountCodesList.size(); i += maxSize) {
            subLists.add(accountCodesList.subList(i, Math.min(i + maxSize, accountCodesList.size())));
        }
        return subLists;
    }

    public Map<String, Object> getFilters(Map<String, String> entityAndFilterColumn) {
        Map<String, Object> result = new LinkedHashMap<>();
        entityAndFilterColumn.forEach((key, value) -> {
            log.info(" key -----------------------------" + key);
            List<NotificationDetails> notificationDetailsList = notificationRepository.findAllByIsProcessedAndSourceSystemAndEntityName(
                "N", "panda", key);
            List<String> filters = new ArrayList<>();

            for (NotificationDetails notificationDetails : notificationDetailsList) {
                try {
                    if ("N".equals(notificationDetails.getIsProcessed())) {
                        processNotificationDetails(notificationDetails, value, filters);
                    } else if ("Y".equals(notificationDetails.getIsProcessed())) {
                        // Log a message when isProcessed is "Y"
                        log.info("Skipping processing for NotificationDetails with isProcessed = Y");
                        // Skip to the next iteration
                    }
                } catch (JsonProcessingException e) {
                    // Log the exception without throwing it
                    log.error("Error processing NotificationDetails", e);
                }
            }
            result.put(value, filters);
        });

        return result;
    }

    private void processNotificationDetails(NotificationDetails notificationDetails, String value, List<String> filters)
    throws JsonProcessingException {
        notificationDetails.getKeysAsMap().forEach((key2, value2) -> {
            if (value.equals(key2)) {
                eventTypemap.put(value2, notificationDetails.getEventType());
                filters.add(value2);
            }
        });
    }

    private void updateStatus(LoadDto loadDto, String status) {
        LoadEntity loadEntity = LoadService.getByRunId(loadDto.getRunId());
        if (status.equals("SUCCESS")) {
            loadEntity.setTransformingStatus(DataLoadTransformingStatuses.COMPLETED);
        } else {
            loadEntity.setTransformingStatus(DataLoadTransformingStatuses.INTERRUPTED);
        }
        log.info("runId : " + loadEntity.getRunId() + " transformingStatus: " + loadEntity.getTransformingStatus() + "\n");
    }

    public Map<String, String> getEventTypeMap() {
        return eventTypemap;
    }

    // Stub methods for missing dependencies
    private LoadDto insertLoad(String queryName) {
        // Implementation here
        return new LoadDto();
    }

    private String getCurrentFilter(Map<String, String> entityAndFilterColumn) {
        // Implementation here
        return "";
    }

    private List<String> extractKeysFromQuery(String graphQLQuery, String operationName) {
        // Implementation here
        return new ArrayList<>();
    }

    private String storeDataInTXT(String graphQLResponse, List<String> headers, Map<String, String> eventTypeMap, LoadDto loadDto, String operationName, String currentFilter) {
        // Implementation here
        return "";
    }

    // Add other dependencies and necessary methods here...
}
