import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;
import lombok.AccessLevel;
import lombok.experimental.FieldDefaults;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.listener.MessageListener;
import org.springframework.kafka.support.Acknowledgment;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

@Slf4j
@Service
@FieldDefaults(level = AccessLevel.PRIVATE, makeFinal = true)
public class PandaNotificationListener implements MessageListener<String, String> {

    CustomKafkaListenerRegistry customKafkaListenerRegistry;
    PandaListenerService pandaListenerService;
    List<ConsumerRecord<String, String>> recordList = new ArrayList<>();
    ConcurrentMap<Long, Acknowledgment> ackMap = new ConcurrentHashMap<>();

    public PandaNotificationListener(CustomKafkaListenerRegistry customKafkaListenerRegistry,
                                     final PandaListenerService pandaListenerService) {
        this.customKafkaListenerRegistry = customKafkaListenerRegistry;
        this.pandaListenerService = pandaListenerService;
    }

    @Scheduled(cron = "0 00 05 * * ?") // Runs daily at 5 AM
    public void consumeFromKafka() throws BusinessException {
        log.info("The Kafka listener started");
        registerKafkaListener();
    }

    @Override
    public void onMessage(final ConsumerRecord<String, String> consumerRecord) {
        try {
            log.info("Received record with value: " + consumerRecord.value() + " and offset: " + consumerRecord.offset());
            synchronized (recordList) {
                recordList.add(consumerRecord);
            }
            Acknowledgment artificialAck = () -> {
                // Custom logic for acknowledgment
                log.info("Artificial acknowledgment for offset: " + consumerRecord.offset());
                ackMap.remove(consumerRecord.offset());
            };
            handleAcknowledgment(artificialAck, consumerRecord.offset());
        } catch (Exception exception) {
            log.error("Listening to panda data threw an error!", exception);
        }
    }

    public void handleAcknowledgment(Acknowledgment acknowledgment, long offset) {
        if (acknowledgment != null) {
            log.info("Storing acknowledgment for offset: " + offset);
            ackMap.put(offset, acknowledgment);
        } else {
            log.warn("Acknowledgment is null for offset: " + offset);
        }
    }

    public void registerKafkaListener() throws BusinessException {
        String listenerId = "panda-topic-listener-id";
        customKafkaListenerRegistry.registerListenerContainer(listenerId);
    }

    @Scheduled(cron = "0 15 05 * * ?") // Runs daily at 5:15 AM
    public void stopListener() {
        try {
            List<ConsumerRecord<String, String>> recordsToStore;
            synchronized (recordList) {
                recordsToStore = new ArrayList<>(recordList);
                recordList.clear();
            }
            if (!recordsToStore.isEmpty()) {
                pandaListenerService.storeConsumeEventsInDb(recordsToStore);
                for (ConsumerRecord<String, String> record : recordsToStore) {
                    Acknowledgment ack = ackMap.remove(record.offset());
                    if (ack != null) {
                        log.info("Acknowledging record with offset: " + record.offset());
                        ack.acknowledge();
                    } else {
                        log.warn("Acknowledgment for record with offset: " + record.offset() + " is null.");
                    }
                }
            }
        } catch (Exception exception) {
            log.error("Stopping panda listener threw an error!", exception);
        } finally {
            String listenerId = "panda-topic-listener-id";
            customKafkaListenerRegistry.unregisterListenerContainer(listenerId);
        }
    }
}
