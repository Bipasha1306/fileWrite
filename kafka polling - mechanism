Sure, I can modify the code to include the manual polling logic while keeping the existing implementation intact. Hereâ€™s how you can integrate the new polling mechanism with the existing `PandaNotificationListener` class:

```java
import com.fasterxml.jackson.core.JsonProcessingException;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.boot.ApplicationArguments;
import org.springframework.boot.ApplicationRunner;
import org.springframework.kafka.listener.MessageListener;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;

import java.text.ParseException;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Properties;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

@Service
public class PandaNotificationListener implements MessageListener<String, String>, ApplicationRunner {

    private static final Logger log = LoggerFactory.getLogger(PandaNotificationListener.class);

    private final CustomKafkaListenerRegistry customKafkaListenerRegistry;
    private final PandaListenerService pandaListenerService;

    // List to hold messages and a lock for thread safety
    private final List<String> messageBuffer = new ArrayList<>();
    private final Lock bufferLock = new ReentrantLock();

    // Batch size and timeout interval
    private static final int BATCH_SIZE = 300;
    private static final long TIMEOUT_INTERVAL = 1800000; // 30 minutes in milliseconds
    private long lastMessageTime = System.currentTimeMillis();

    private KafkaConsumer<String, String> consumer;
    private final ExecutorService executorService = Executors.newSingleThreadExecutor();

    public PandaNotificationListener(final CustomKafkaListenerRegistry customKafkaListenerRegistry,
                                     final PandaListenerService pandaListenerService) {
        this.customKafkaListenerRegistry = customKafkaListenerRegistry;
        this.pandaListenerService = pandaListenerService;
    }

    @Override
    public void run(final ApplicationArguments args) throws Exception {
        log.info("Listener Started for Panda Notification Service");
        String listenerId = "panda-topic-listener-id";
        customKafkaListenerRegistry.registerListenerContainer(listenerId);

        Properties props = new Properties();
        props.put("bootstrap.servers", "your_kafka_broker:9092");
        props.put("group.id", "panda-topic-listener-id");
        props.put("key.deserializer", StringDeserializer.class.getName());
        props.put("value.deserializer", StringDeserializer.class.getName());
        props.put("auto.offset.reset", "earliest");

        consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList("panda_data_change_alert"));

        executorService.submit(this::pollMessages);
        scheduleTimeoutTask();
    }

    @Override
    public void onMessage(final ConsumerRecord<String, String> data) {
        String message = data.value();
        log.info("Received message: " + message);
        try {
            log.info("Started storing panda details in table");
            pandaListenerService.storeConsumeEventsInDb(message);
        } catch (JsonProcessingException | ParseException e) {
            throw new RuntimeException(e);
        }
    }

    private void pollMessages() {
        try {
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(100);
                for (ConsumerRecord<String, String> record : records) {
                    String message = record.value();
                    log.info("Received message: " + message);

                    bufferLock.lock();
                    try {
                        messageBuffer.add(message);
                        lastMessageTime = System.currentTimeMillis();

                        if (messageBuffer.size() >= BATCH_SIZE) {
                            flushMessages();
                        }
                    } finally {
                        bufferLock.unlock();
                    }
                }
            }
        } catch (Exception e) {
            log.error("Error while polling messages", e);
        }
    }

    @Scheduled(fixedRate = TIMEOUT_INTERVAL) // Check every 30 minutes
    public void scheduleTimeoutTask() {
        bufferLock.lock();
        try {
            if (!messageBuffer.isEmpty() && (System.currentTimeMillis() - lastMessageTime >= TIMEOUT_INTERVAL)) {
                flushMessages();
            }
        } finally {
            bufferLock.unlock();
        }
    }

    private void flushMessages() {
        List<String> messagesToProcess = new ArrayList<>(messageBuffer);
        messageBuffer.clear();

        for (String message : messagesToProcess) {
            try {
                log.info("Started storing panda details in table");
                pandaListenerService.storeConsumeEventsInDb(message);
            } catch (JsonProcessingException | ParseException e) {
                throw new RuntimeException(e);
            }
        }

        log.info("Processed batch of " + messagesToProcess.size() + " messages");
    }
}
```

### Explanation:
1. **Existing Implementation**:
   - The existing `onMessage` method remains unchanged. It processes individual messages as they arrive.
   
2. **Polling Messages**:
   - The `pollMessages` method runs in a separate thread and continuously polls the Kafka topic for new messages.
   - Each received message is added to the `messageBuffer`.

3. **Buffering and Flushing**:
   - If the `messageBuffer` size reaches `BATCH_SIZE`, the `flushMessages` method is called to process and store the messages.
   - The `scheduleTimeoutTask` method is scheduled to run every 30 minutes (`fixedRate = TIMEOUT_INTERVAL`).
   - If the timeout interval has elapsed since the last message was received, the `flushMessages` method is called to process and store the messages.

With these changes, the code will manually poll the Kafka topic, buffer the messages, and flush the messages to the database either when the buffer size reaches 300 messages or after a 30-minute timeout. The existing implementation for handling individual messages is also preserved.
